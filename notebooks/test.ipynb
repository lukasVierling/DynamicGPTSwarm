{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "from openai import OpenAI\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-bmaRXuXoxwcsfDHEF52cF04c8aF849A4B6D7E7Da439e8c30\",\n",
    "    base_url=\"https://www.plus7.plus/v1\"\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"你今天过怎么样!\"}\n",
    "  ],\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好! 我是一个语言模型助手,很高兴能够帮助您。我能为您做些什么呢?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "message = completion.choices[0].message\n",
    "content = unicodedata.normalize('NFKC', message.content)\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "initial_probability = 0.5\n",
    "potential_connections = [1, 2, 3, 4, 5]\n",
    "init_logit = torch.log(torch.tensor(initial_probability / (1 - initial_probability)))\n",
    "init_tensor = torch.ones(\n",
    "    len(potential_connections),\n",
    "    requires_grad=True) * init_logit\n",
    "probs = torch.sigmoid(init_tensor)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "        0.1000], requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define the dimensions\n",
    "input_dim = 10\n",
    "output_dim = 10\n",
    "\n",
    "# Initialize the linear layer\n",
    "linear_layer = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "# Initialize weights with zeros\n",
    "nn.init.zeros_(linear_layer.weight)\n",
    "\n",
    "# Initialize bias with 1/k\n",
    "nn.init.constant_(linear_layer.bias, 1/output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000, Loss: 1.542632958262402e-06\n",
      "Epoch 20/1000, Loss: 1.4812758308835328e-06\n",
      "Epoch 30/1000, Loss: 1.4224940514395712e-06\n",
      "Epoch 40/1000, Loss: 1.36602352540649e-06\n",
      "Epoch 50/1000, Loss: 1.3123379858370754e-06\n",
      "Epoch 60/1000, Loss: 1.2602976084963302e-06\n",
      "Epoch 70/1000, Loss: 1.2106669373679324e-06\n",
      "Epoch 80/1000, Loss: 1.1630868357315194e-06\n",
      "Epoch 90/1000, Loss: 1.1169078106831876e-06\n",
      "Epoch 100/1000, Loss: 1.0725868833105778e-06\n",
      "Epoch 110/1000, Loss: 1.0300623216608074e-06\n",
      "Epoch 120/1000, Loss: 9.896845085677342e-07\n",
      "Epoch 130/1000, Loss: 9.508611356068286e-07\n",
      "Epoch 140/1000, Loss: 9.133629532698251e-07\n",
      "Epoch 150/1000, Loss: 8.772315709393297e-07\n",
      "Epoch 160/1000, Loss: 8.425042778981151e-07\n",
      "Epoch 170/1000, Loss: 8.097084105429531e-07\n",
      "Epoch 180/1000, Loss: 7.78026219450112e-07\n",
      "Epoch 190/1000, Loss: 7.474338872270891e-07\n",
      "Epoch 200/1000, Loss: 7.179356202868803e-07\n",
      "Epoch 210/1000, Loss: 6.895426736264199e-07\n",
      "Epoch 220/1000, Loss: 6.622772730224824e-07\n",
      "Epoch 230/1000, Loss: 6.368534855027974e-07\n",
      "Epoch 240/1000, Loss: 6.123766524979146e-07\n",
      "Epoch 250/1000, Loss: 5.885166274310905e-07\n",
      "Epoch 260/1000, Loss: 5.65233335692028e-07\n",
      "Epoch 270/1000, Loss: 5.426122129392752e-07\n",
      "Epoch 280/1000, Loss: 5.210447397985263e-07\n",
      "Epoch 290/1000, Loss: 5.005161938242964e-07\n",
      "Epoch 300/1000, Loss: 4.810709128832968e-07\n",
      "Epoch 310/1000, Loss: 4.6246614715528267e-07\n",
      "Epoch 320/1000, Loss: 4.4485261696536327e-07\n",
      "Epoch 330/1000, Loss: 4.276739957731479e-07\n",
      "Epoch 340/1000, Loss: 4.1112758708550246e-07\n",
      "Epoch 350/1000, Loss: 3.950802636154549e-07\n",
      "Epoch 360/1000, Loss: 3.7952924003548105e-07\n",
      "Epoch 370/1000, Loss: 3.64943304020926e-07\n",
      "Epoch 380/1000, Loss: 3.5087441574432887e-07\n",
      "Epoch 390/1000, Loss: 3.372558978753659e-07\n",
      "Epoch 400/1000, Loss: 3.2414189377050207e-07\n",
      "Epoch 410/1000, Loss: 3.114848823315697e-07\n",
      "Epoch 420/1000, Loss: 2.9935330303487717e-07\n",
      "Epoch 430/1000, Loss: 2.877198426176619e-07\n",
      "Epoch 440/1000, Loss: 2.763871123079298e-07\n",
      "Epoch 450/1000, Loss: 2.6548889309196966e-07\n",
      "Epoch 460/1000, Loss: 2.5503089773337706e-07\n",
      "Epoch 470/1000, Loss: 2.4519667363165354e-07\n",
      "Epoch 480/1000, Loss: 2.359389128514522e-07\n",
      "Epoch 490/1000, Loss: 2.269812853228359e-07\n",
      "Epoch 500/1000, Loss: 2.1832319418990664e-07\n",
      "Epoch 510/1000, Loss: 2.0999831917833944e-07\n",
      "Epoch 520/1000, Loss: 2.0212689832987962e-07\n",
      "Epoch 530/1000, Loss: 1.9443389476236916e-07\n",
      "Epoch 540/1000, Loss: 1.8719400429745292e-07\n",
      "Epoch 550/1000, Loss: 1.801640792109538e-07\n",
      "Epoch 560/1000, Loss: 1.7332811808046245e-07\n",
      "Epoch 570/1000, Loss: 1.666343365513967e-07\n",
      "Epoch 580/1000, Loss: 1.6016743131785915e-07\n",
      "Epoch 590/1000, Loss: 1.5395727359646116e-07\n",
      "Epoch 600/1000, Loss: 1.4793117486533447e-07\n",
      "Epoch 610/1000, Loss: 1.4222879940462008e-07\n",
      "Epoch 620/1000, Loss: 1.3680923416359292e-07\n",
      "Epoch 630/1000, Loss: 1.3162204481886874e-07\n",
      "Epoch 640/1000, Loss: 1.2655193870614312e-07\n",
      "Epoch 650/1000, Loss: 1.2158997719780018e-07\n",
      "Epoch 660/1000, Loss: 1.1679644273954182e-07\n",
      "Epoch 670/1000, Loss: 1.1224253171349119e-07\n",
      "Epoch 680/1000, Loss: 1.0793608140602373e-07\n",
      "Epoch 690/1000, Loss: 1.0374374426191935e-07\n",
      "Epoch 700/1000, Loss: 9.979915205349243e-08\n",
      "Epoch 710/1000, Loss: 9.608459805576786e-08\n",
      "Epoch 720/1000, Loss: 9.2523094963326e-08\n",
      "Epoch 730/1000, Loss: 8.91096618715892e-08\n",
      "Epoch 740/1000, Loss: 8.587880273580595e-08\n",
      "Epoch 750/1000, Loss: 8.275839746829661e-08\n",
      "Epoch 760/1000, Loss: 7.975494042966602e-08\n",
      "Epoch 770/1000, Loss: 7.685163438964082e-08\n",
      "Epoch 780/1000, Loss: 7.403597379607163e-08\n",
      "Epoch 790/1000, Loss: 7.127624002123412e-08\n",
      "Epoch 800/1000, Loss: 6.87188830283958e-08\n",
      "Epoch 810/1000, Loss: 6.623061921118278e-08\n",
      "Epoch 820/1000, Loss: 6.37991632856938e-08\n",
      "Epoch 830/1000, Loss: 6.143134356761948e-08\n",
      "Epoch 840/1000, Loss: 5.912972866894961e-08\n",
      "Epoch 850/1000, Loss: 5.6877098586483044e-08\n",
      "Epoch 860/1000, Loss: 5.4677634864219726e-08\n",
      "Epoch 870/1000, Loss: 5.256485735571914e-08\n",
      "Epoch 880/1000, Loss: 5.053902896179352e-08\n",
      "Epoch 890/1000, Loss: 4.859490587705295e-08\n",
      "Epoch 900/1000, Loss: 4.676358855704166e-08\n",
      "Epoch 910/1000, Loss: 4.505203321514273e-08\n",
      "Epoch 920/1000, Loss: 4.340987658224549e-08\n",
      "Epoch 930/1000, Loss: 4.1815713558435164e-08\n",
      "Epoch 940/1000, Loss: 4.030182054748366e-08\n",
      "Epoch 950/1000, Loss: 3.8887169040435765e-08\n",
      "Epoch 960/1000, Loss: 3.753397948003112e-08\n",
      "Epoch 970/1000, Loss: 3.620699828843499e-08\n",
      "Epoch 980/1000, Loss: 3.5014188881632435e-08\n",
      "Epoch 990/1000, Loss: 3.3844685276562814e-08\n",
      "Epoch 1000/1000, Loss: 3.2693332485678184e-08\n",
      "tensor([ 9.2704e-01,  4.6388e-03,  2.2080e-02, -1.2342e+00,  4.6944e-02,\n",
      "         7.4885e-01, -1.5430e-01,  5.2466e-01,  2.9180e-04,  8.1042e-01])\n",
      "tensor([ 4.7810,  2.0139,  2.0662, -1.7026,  2.1408,  4.2463,  1.5371,  3.5737,\n",
      "         2.0008,  4.4311], grad_fn=<ViewBackward0>)\n",
      "tensor([ 4.7811,  2.0139,  2.0662, -1.7026,  2.1408,  4.2466,  1.5371,  3.5740,\n",
      "         2.0009,  4.4313])\n"
     ]
    }
   ],
   "source": [
    "# Create dummy input data\n",
    "x = torch.randn(1000, 10)\n",
    "\n",
    "# Create dummy output data\n",
    "def y_func(x):\n",
    "    return 3*x + 2\n",
    "y = y_func(x)\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(linear_layer.parameters(), lr=0.01)\n",
    "\n",
    "# Number of epochs\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    y_pred = linear_layer(x)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = loss_fn(y_pred, y)\n",
    "\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n",
    "\n",
    "x_test = torch.randn(10)\n",
    "print(x_test)\n",
    "print(linear_layer(x_test))\n",
    "print(y_func(x_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptswarm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
