{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-11 11:43:00,957\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/lucas/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2,3,4,5,6,7\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModel, AutoTokenizer, pipeline, AutoModelForCausalLM\n",
    "from swarm.optimizer.edge_optimizer.edge_network import EdgeNetwork\n",
    "from swarm.optimizer.edge_optimizer.parameterization import EdgeWiseDistributionByModel\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from swarm.graph.swarm import Swarm\n",
    "from typing import List, Any, Optional\n",
    "\n",
    "from swarm.llm.custom_llm import CustomLLM\n",
    "from swarm.llm.format import Message\n",
    "\n",
    "from vllm import LLM, SamplingParams\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from experiments.evaluator.datasets.mmlu_dataset import MMLUDataset\n",
    "from experiments.evaluator.datasets.cmmlu_dataset import CMMLUDataset\n",
    "from experiments.evaluator.datasets.mixedmmlu_dataset import MixedMMLUDataset\n",
    "import pickle\n",
    "import json\n",
    "import asyncio\n",
    "import json\n",
    "from huggingface_hub import login \n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import io\n",
    "\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cuda:7')\n",
    "        else:\n",
    "            return super().find_class(module, name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixedmmlu_8true_0adv_noedge_iter200_domain_mixedmmlu_MajorityVote_OptimizedSwarm_1714795470.0560036.pkl\n",
      "0.421\n"
     ]
    }
   ],
   "source": [
    "path = \"mixedmmlu_8true_0adv_noedge_iter200_domain_mixedmmlu_MajorityVote_OptimizedSwarm_1714795470.0560036\" + \".pkl\"\n",
    "full_path =f\"result/mmlu/specialized_agents/ba_runs_reduce_edge/{path}\"\n",
    "with open(full_path, 'rb') as f:\n",
    "    swarm = pickle.load(f)  # Load the swarm\n",
    "    #swarm = CPU_Unpickler(f).load()\n",
    "    #delete swarm object and clear memory\n",
    "    score = pickle.load(f)  # Load the score\n",
    "    pickle_object = {'swarm': swarm, 'score': score}\n",
    "print(path)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<swarm.graph.swarm.Swarm object at 0x71ab9c973610>\n"
     ]
    }
   ],
   "source": [
    "print(swarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "for i,node in enumerate(swarm.composite_graph.nodes.values()):\n",
    "    if i ==0:\n",
    "        continue\n",
    "    print(node.llm.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('edge_logits', tensor([-0.9060, -2.0771, -0.3538, -1.9184, -2.3243, -3.0701, -3.8445, -3.8105,\n",
      "        -2.0401, -1.5536, -2.3212, -4.7880, -1.9222, -1.7154, -4.7214, -2.5089,\n",
      "        -2.1340,  0.9295, -2.5914,  1.2137, -2.2820, -2.1987, -3.1128,  0.2236,\n",
      "        -1.2063, -2.0589, -4.0054, -1.2779, -2.5772, -4.5234, -2.2227, -1.8173,\n",
      "        -3.7507, -2.4876, -0.0229, -2.1858])), ('order_params', tensor([ 0.2713, -1.2729,  0.5027,  0.4181, -0.6394, -0.6608, -0.1433, -0.1043,\n",
      "        -1.5313]))])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(f\"result/crosswords/old_method_10_it_nostuck_20batch/experiment8_edge_logits_9.pt\", 'rb') as f:\n",
    "    edge_logits = torch.load(f)  # Load the swarm\n",
    "    #delete swarm object and clear memory\n",
    "print(edge_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using custom LLM class, model_name: meta-llama/Meta-Llama-3-8B-Instruct\n",
      "Load Model...\n",
      "Selected GPU: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.64s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m swarm \u001b[38;5;241m=\u001b[39m \u001b[43mSwarm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCrosswordsBruteForceOpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCrosswordsReflection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcrosswords\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta-llama/Meta-Llama-3-8B-Instruct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#\"google/gemma-7B-it\",#,#\"gpt-3.5-turbo-1106\", #\"gpt-4-1106-preview\" ,  #\"CrosswordsToT\",\"CrosswordsBruteForceOpt\",\"CrosswordsReflection\"\u001b[39;49;00m\n\u001b[1;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfinal_node_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReturnAll\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfinal_node_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43medge_optimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43minit_connection_probability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconnect_output_nodes_to_final_node\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43minclude_inner_agent_connections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43medge_network_enable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mllm_backbone_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m swarm\u001b[38;5;241m.\u001b[39mconnection_dist\u001b[38;5;241m.\u001b[39medge_logits \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mParameter(edge_logits[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_logits\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/DynamicGPTSwarm/swarm/graph/swarm.py:63\u001b[0m, in \u001b[0;36mSwarm.__init__\u001b[0;34m(self, agent_names, domain, model_name, open_graph_as_html, final_node_class, final_node_kwargs, edge_optimize, node_optimize, init_connection_probability, connect_output_nodes_to_final_node, include_inner_agent_connections, edge_network_enable, llm_backbone_name, price_list)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_backbone_name \u001b[38;5;241m=\u001b[39m llm_backbone_name\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprice_list \u001b[38;5;241m=\u001b[39m price_list\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morganize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude_inner_agent_connections\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DynamicGPTSwarm/swarm/graph/swarm.py:68\u001b[0m, in \u001b[0;36mSwarm.organize\u001b[0;34m(self, include_inner_agent_connections)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21morganize\u001b[39m(\u001b[38;5;28mself\u001b[39m, include_inner_agent_connections: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mused_agents \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 68\u001b[0m     decision_method \u001b[38;5;241m=\u001b[39m \u001b[43mOperationRegistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_node_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_node_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomposite_graph \u001b[38;5;241m=\u001b[39m CompositeGraph(decision_method,\n\u001b[1;32m     70\u001b[0m                                           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name)\n\u001b[1;32m     71\u001b[0m     potential_connections \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/DynamicGPTSwarm/swarm/environment/operations/operation_registry.py:20\u001b[0m, in \u001b[0;36mOperationRegistry.get\u001b[0;34m(cls, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mcls\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Node:\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/class_registry/registry.py:114\u001b[0m, in \u001b[0;36mBaseRegistry.get\u001b[0;34m(self, key, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    Creates a new instance of the class matching the specified key.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m      - :py:meth:`__init__`\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/class_registry/registry.py:145\u001b[0m, in \u001b[0;36mBaseRegistry.create_instance\u001b[0;34m(class_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_instance\u001b[39m(class_, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;66;03m# type: (type, *Any, **Any) -> Any\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Prepares the return value for :py:meth:`get`.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m        Keyword arguments passed to :py:meth:`get`.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclass_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DynamicGPTSwarm/swarm/environment/operations/crosswords/return_all.py:24\u001b[0m, in \u001b[0;36mReturnAll.__init__\u001b[0;34m(self, domain, model_name, operation_description, id, best_state)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(operation_description, \u001b[38;5;28mid\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain \u001b[38;5;241m=\u001b[39m domain\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm \u001b[38;5;241m=\u001b[39m \u001b[43mLLMRegistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt_set \u001b[38;5;241m=\u001b[39m PromptSetRegistry\u001b[38;5;241m.\u001b[39mget(domain)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_state \u001b[38;5;241m=\u001b[39m best_state\n",
      "File \u001b[0;32m~/DynamicGPTSwarm/swarm/llm/llm_registry.py:30\u001b[0m, in \u001b[0;36mLLMRegistry.get\u001b[0;34m(cls, model_name)\u001b[0m\n\u001b[1;32m     27\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mregistry\u001b[38;5;241m.\u001b[39mget(model_name)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m CUSTOM_LLMS:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# for custom model get the smalle gemma model and run on our gpus\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCustomLLM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# any version of GPTChat like \"gpt-4-1106-preview\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mregistry\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPTChat\u001b[39m\u001b[38;5;124m'\u001b[39m, model_name)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/class_registry/registry.py:114\u001b[0m, in \u001b[0;36mBaseRegistry.get\u001b[0;34m(self, key, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    Creates a new instance of the class matching the specified key.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m      - :py:meth:`__init__`\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/class_registry/registry.py:145\u001b[0m, in \u001b[0;36mBaseRegistry.create_instance\u001b[0;34m(class_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_instance\u001b[39m(class_, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;66;03m# type: (type, *Any, **Any) -> Any\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Prepares the return value for :py:meth:`get`.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m        Keyword arguments passed to :py:meth:`get`.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclass_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DynamicGPTSwarm/swarm/llm/custom_llm.py:82\u001b[0m, in \u001b[0;36mCustomLLM.__init__\u001b[0;34m(self, model_name)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (CustomLLM\u001b[38;5;241m.\u001b[39mMAX_LLMS):\n\u001b[1;32m     81\u001b[0m         CustomLLM\u001b[38;5;241m.\u001b[39mdevices[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name][i] \u001b[38;5;241m=\u001b[39m select_gpu()\n\u001b[0;32m---> 82\u001b[0m         CustomLLM\u001b[38;5;241m.\u001b[39mmodels[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name][i] \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mCustomLLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m CustomLLM\u001b[38;5;241m.\u001b[39mtokenizers:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoad Tokenizer...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/gptswarm/lib/python3.10/site-packages/transformers/modeling_utils.py:2556\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2551\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2552\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2553\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2554\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2555\u001b[0m         )\n\u001b[0;32m-> 2556\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gptswarm/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gptswarm/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gptswarm/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gptswarm/lib/python3.10/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/envs/gptswarm/lib/python3.10/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "swarm = Swarm([\"CrosswordsBruteForceOpt\",\"CrosswordsReflection\"], \"crosswords\", \"meta-llama/Meta-Llama-3-8B-Instruct\",#\"google/gemma-7B-it\",#,#\"gpt-3.5-turbo-1106\", #\"gpt-4-1106-preview\" ,  #\"CrosswordsToT\",\"CrosswordsBruteForceOpt\",\"CrosswordsReflection\"\n",
    "            final_node_class=\"ReturnAll\", \n",
    "            final_node_kwargs={},\n",
    "            edge_optimize=True,\n",
    "            init_connection_probability=0.1, \n",
    "            connect_output_nodes_to_final_node=True, \n",
    "            include_inner_agent_connections=True,\n",
    "            edge_network_enable=False,\n",
    "            llm_backbone_name=\"\")\n",
    "swarm.connection_dist.edge_logits = nn.Parameter(edge_logits['edge_logits'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph, _ = swarm.connection_dist.realize(swarm.composite_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<swarm.graph.composite_graph.CompositeGraph object at 0x77b3347eda80>\n"
     ]
    }
   ],
   "source": [
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swarm.graph.visualize import GPTSwarmVis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "/home/lucas/DynamicGPTSwarm/result/example.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "GPTSwarmVis(graph, file_name = \"result.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from swarm.graph.swarm import Swarm\n",
    "from swarm.environment.operations.final_decision import MergingStrategy\n",
    "from experiments.evaluator.evaluator import Evaluator\n",
    "from experiments.evaluator.datasets.mmlu_dataset import MMLUDataset\n",
    "from dataset.MMLU.download import download\n",
    "from experiments.evaluator.datasets.cmmlu_dataset import CMMLUDataset\n",
    "from experiments.evaluator.datasets.mixedmmlu_dataset import MixedMMLUDataset\n",
    "from dataset.CMMLU.download import download as cmmlu_download\n",
    "\n",
    "from swarm.llm.custom_llm import CustomLLM\n",
    "\n",
    "swarm = Swarm(\n",
    "    [\"IO\"],\n",
    "    \"mmlu\",\n",
    "    model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    final_node_class=\"FinalDecision\",\n",
    "    final_node_kwargs=dict(strategy=MergingStrategy.MajorityVote),\n",
    "    edge_optimize=True,\n",
    "    edge_network_enable=False,\n",
    "    llm_backbone_name=\"google/gemma-2B\",\n",
    ")\n",
    "print(swarm.connection_dist.edge_logits.shape)\n",
    "#got the swarm, now evaluator\n",
    "dataset_train = MMLUDataset('dev', categories=[\"college_mathematics\",\"elementary_mathematics\",\"formal_logic\", \"abstract_algebra\", \"high_school_mathematics\"])\n",
    "dataset_val = MMLUDataset('val',categories=[\"college_mathematics\",\"elementary_mathematics\",\"formal_logic\", \"abstract_algebra\", \"high_school_mathematics\"])\n",
    "evaluator = Evaluator(\n",
    "    swarm,\n",
    "    dataset_val,\n",
    "    dataset_val,\n",
    "    model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    enable_tensorboard = False,\n",
    "    enable_artifacts=True,\n",
    "    tensorboard_tag=None)\n",
    "accs = {}\n",
    "accs['IO'] = await evaluator.evaluate_agent(agent=\"IO\", limit_questions=25)\n",
    "accs['COT'] = await evaluator.evaluate_agent(agent=\"COT\", limit_questions=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = [0.1, 0.3, 0.1, 0.1, 0.1, 0.2, 0.2, 0.3, 0.1, 0.4, 0.1, 0.2, 0.2, 0.3, 0.1, 0.0, 0.1, 0.0, 0.1, 0.1, 0.1, 0.1, 0.2, 0.1, 0.0, 0.4, 0.2, 0.1, 0.1, 0.2, 0.4, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.1, 0.1, 0.0, 0.4, 0.2, 0.1, 0.0, 0.1, 0.1, 0.2, 0.3, 0.4, 0.5, 0.1, 0.1, 0.2, 0.1, 0.1, 0.1, 0.1, 0.0, 0.3, 0.1, 0.4, 0.1, 0.1, 0.2, 0.0, 0.0, 0.3, 0.2, 0.3, 0.1, 0.2, 0.4, 0.1, 0.2, 0.0, 0.2, 0.2, 0.0, 0.2, 0.1]\n",
    "\n",
    "data = [[i for i in data[j:j+20]]for j in range(len(data)//20)]\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = torch.nn.Linear(2048,36)\n",
    "path = \"result/crosswords/experiment8_edge_logits_0.pt\"\n",
    "dict = torch.load(path)\n",
    "for key in dict.keys():\n",
    "    print(key)\n",
    "    print(dict[key].shape)\n",
    "    print(dict[key])\n",
    "    print(\"----\")\n",
    "lin.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result/crosswords/experiment9_edge_network-False_final_utilities.pkl', 'rb') as f:\n",
    "    utilities = pkl.load(f)\n",
    "print(utilities.keys())\n",
    "for key in utilities.keys():\n",
    "    if key !=\"utilities\":\n",
    "        print(key, \" \", utilities[key])\n",
    "with open('result/crosswords/experiment9_edge_network-True_final_utilities.pkl', 'rb') as f:\n",
    "    utilities = pkl.load(f)\n",
    "print(utilities.keys())\n",
    "for key in utilities.keys():\n",
    "    if key !=\"utilities\":\n",
    "        print(key, \" \", utilities[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result/crosswords/experiment9_edge_network-False_final_utilities.pkl', 'rb') as f:\n",
    "    utilities = pkl.load(f)\n",
    "print(utilities.keys())\n",
    "for key in utilities.keys():\n",
    "    if key !=\"utilities\":\n",
    "        print(key, \" \", utilities[key])\n",
    "\n",
    "#turn every mean into max 3 decimals after comma\n",
    "\n",
    "utilities['mean_utilities_per_run'] = [round(i,3) for i in utilities['mean_utilities_per_run']]\n",
    "utilities['overall_mean'] = round(np.mean(utilities['mean_utilities_per_run'], axis=0),3)\n",
    "utilities['overall_std'] = round(np.std(utilities['mean_utilities_per_run'], axis=0),3)\n",
    "print(utilities['overall_mean'])\n",
    "print(utilities['overall_std'])\n",
    "print(utilities['mean_utilities_per_run'])\n",
    "#dump results\n",
    "with open('result/crosswords/experiment9_edge_network-False_final_utilities.pkl', 'wb') as f:\n",
    "    pkl.dump(utilities, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = CrosswordsEvaluator(test_data, batch_size=batch_size, metric=\"words\", window_size=num_batches)\n",
    "swarm = Swarm([\"CrosswordsBruteForceOpt\",\"CrosswordsReflection\"], \"crosswords\", \"meta-llama/Meta-Llama-3-8B-Instruct\",#\"google/gemma-7B-it\",#,#\"gpt-3.5-turbo-1106\", #\"gpt-4-1106-preview\" ,  #\"CrosswordsToT\",\"CrosswordsBruteForceOpt\",\"CrosswordsReflection\"\n",
    "            final_node_class=\"ReturnAll\", \n",
    "            final_node_kwargs={},\n",
    "            edge_optimize=True,\n",
    "            init_connection_probability=init_connection_probability, \n",
    "            connect_output_nodes_to_final_node=True, \n",
    "            include_inner_agent_connections=True,\n",
    "            edge_network_enable=edge_network_enable,\n",
    "            llm_backbone_name=llm_backbone_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_messages(messages: List[Message]) -> List[Message]:\n",
    "        processed_messages = []\n",
    "        system_message = None\n",
    "\n",
    "        for message in messages:\n",
    "            if message.role == 'system':\n",
    "                system_message = message.content\n",
    "            elif message.role == 'user':\n",
    "                if system_message:\n",
    "                    message.content = system_message + ' ' + message.content\n",
    "                    system_message = None\n",
    "                processed_messages.append(message)\n",
    "\n",
    "        # Handle the case where the last message is a system message\n",
    "        if system_message:\n",
    "            processed_messages.append(Message(role='user', content=system_message))\n",
    "\n",
    "        return processed_messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load gemma-7B-it with Custom LLM class\n",
    "\n",
    "from swarm.environment.prompt.prompt_set_registry import PromptSetRegistry\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = CustomLLM(\"google/gemma-7B-it\" )\n",
    "test_dataset = MMLUDataset(\"test\")\n",
    "prompt_set = PromptSetRegistry.get(\"cmmlu\")\n",
    "\n",
    "#test_dataset._total_df = test_dataset._total_df[:20]\n",
    "\n",
    "tqdm = tqdm(test_dataset)\n",
    "\n",
    "\n",
    "y = []\n",
    "\n",
    "for sample in tqdm:\n",
    "    input = test_dataset.record_to_swarm_input(sample)\n",
    "    role = prompt_set.get_role()\n",
    "    constraint = prompt_set.get_constraint()\n",
    "    message = [Message(role=\"system\", content=f\"You are a {role}. {constraint}\"),Message(role=\"user\", content=input[\"task\"])]\n",
    "\n",
    "    input_dict = process_messages(message)\n",
    "    answer = model.gen(message)\n",
    "    answer = test_dataset.postprocess_answer(answer)\n",
    "    correct_answer = test_dataset.record_to_target_answer(sample)\n",
    "    y.append(answer == correct_answer)\n",
    "print(\"final accuracy: \", np.mean(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_chat_template(messages, add_generation_prompt=True):\n",
    "    if add_generation_prompt:\n",
    "        if messages[-1][\"role\"] == \"user\":\n",
    "            messages.append({\"role\": \"assistant\", \"content\": \"\"})\n",
    "    chat = \"\"\n",
    "    for message in messages:\n",
    "        print(message)\n",
    "        role, content = message.values()\n",
    "        print(role, content)\n",
    "        if role == \"user\":\n",
    "            chat += f\"[|Human|]:{content}\"\n",
    "        elif role == \"assistant\":\n",
    "            chat += f\"[|AI|]:{content}\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown role {role}\")\n",
    "    return chat\n",
    "tokenizer.apply_chat_template = apply_chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"result/crosswords/old_method_10_it_nostuck_20batch/experiment8_utilities_9.pkl\", \"rb\") as f:\n",
    "    utilities = pkl.load(f)\n",
    "#print(utilities[100:])\n",
    "print(np.mean(utilities[100:]))\n",
    "for i in range(0,200,20):\n",
    "    print(utilities[i:i+20])\n",
    "    print(np.mean(utilities[i:i+20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.sigmoid(swarm['edge_logits']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adjacency_matrix(edge_probs, swarm):\n",
    "    assert swarm is not None\n",
    "\n",
    "    # Create an empty adjacency matrix\n",
    "    num_nodes = len(swarm.composite_graph.nodes)\n",
    "    adjacency_matrix = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "    # Create a dictionary to map indices to nodes\n",
    "    node_indices = {}\n",
    "    node_names = {}\n",
    "    for index, (node_id, node_ref) in enumerate(swarm.composite_graph.nodes.items()):\n",
    "        node_indices[node_id] = index\n",
    "        node_names[node_id] = node_ref.node_name\n",
    "\n",
    "    # Iterate over the connections and probabilities\n",
    "    for conn, prob in zip(swarm.connection_dist.potential_connections, edge_probs):\n",
    "        src_id, dst_id = conn\n",
    "        src_index = node_indices[src_id]\n",
    "        dst_index = node_indices[dst_id]\n",
    "        adjacency_matrix[src_index, dst_index] = prob.item()\n",
    "\n",
    "    return adjacency_matrix, node_indices, node_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_conns(edge_probs: torch.Tensor, swarm):\n",
    "    assert swarm is not None\n",
    "    msgs = []\n",
    "    for i_conn, (conn, prob) in enumerate(zip(\n",
    "            swarm.connection_dist.potential_connections, edge_probs)):\n",
    "        src_id, dst_id = conn\n",
    "        src_node = swarm.composite_graph.find_node(src_id)\n",
    "        dst_node = swarm.composite_graph.find_node(dst_id)\n",
    "        src_node_name =  src_node.model_name if hasattr(src_node,\"model_name\") else src_node.node_name\n",
    "        dst_node_name = dst_node.model_name if hasattr(dst_node,\"model_name\") else dst_node.node_name#\n",
    "        msg = (f\"{i_conn}: src={src_node_name}({src_node.id}), \"\n",
    "                f\"dst={dst_node_name}({dst_node.id}), prob={prob.item():.3f}\")\n",
    "        msgs.append(msg+\"\\n\")\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math = {'question': ['Let A be the set of all ordered pairs of integers (m, n) such that 7m + 12n = 22. What is the greatest negative number in the set B = {m + n : (m, n) \\in A}?'],\n",
    "'A': ['-5'],\n",
    "'B': ['-4'],\n",
    "'C': ['-3'],\n",
    "'D': ['-2'],\n",
    "'Solution': ['B']\n",
    "}\n",
    "logic = {\n",
    "    'question': ['Construct a complete truth table for the following pairs of propositions. Then, using the truth tables, determine whether the statements are logically equivalent or contradictory. If neither, determine whether they are consistent or inconsistent. Justify your answers. E ⊃ (F · E) and ~E · F'],\n",
    "    'A': ['Logically equivalent'],\n",
    "    'B': ['Contradictory'],\n",
    "    'C': ['Neither logically equivalent nor contradictory, but consistent'],\n",
    "    'D': ['Inconsistent'],\n",
    "    'Solution': ['C']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics:  67\n",
      "Total number of questions:  11649\n",
      "Total df length: 11649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Initialize list to store distances and corresponding records\\ndistances = []\\n\\nfor record in dataset_val:\\n    record_copy = copy.deepcopy(record)\\n    record_df = pd.DataFrame([record_copy])\\n    input_dict = dataset_val.record_to_swarm_input(record_df)\\n    edge_probs = swarm.connection_dist.get_edge_probs(swarm.composite_graph, inputs=input_dict)\\n    \\n    # Calculate distance to the mean\\n    distance = torch.norm(edge_probs - mean_edge_probs)\\n    \\n    # Store distance and record\\n    distances.append((distance, record_copy, edge_probs))\\n# Sort distances in descending order and keep top 10\\ntop_10_records = sorted(distances, key=lambda x: x[0], reverse=True)[:10]\\n\\n# Extract records from tuples\\ntop_10_records = [(record, edge_probs) for _, record, edge_probs  in top_10_records]\\nprint(\"top10:\")\\nfor record,probs in top_10_records:\\n    print(\"Question: \", record)\\n    _print_conns(probs, swarm)\\n    print(\"Subtracting the mean: \")\\n    _print_conns(mean_edge_probs-probs ,swarm)\\n    print(\"----NExt-----\")\\n    '"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "dataset_val = CMMLUDataset('test')\n",
    "print(\"Total df length:\", len(dataset_val._total_df))\n",
    "#dataset_val._total_df = dataset_val._total_df[:3000]\n",
    "all_probs = []\n",
    "swarm.connection_dist.model.eval()\n",
    "\n",
    "# Initialize list to store all edge_probs\n",
    "all_edge_probs = []\n",
    "swarm.connection_dist.model.eval()\n",
    "\n",
    "for i, record in enumerate(dataset_val):\n",
    "    record = pd.DataFrame([record])\n",
    "    input_dict = dataset_val.record_to_swarm_input(record)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        edge_probs = swarm.connection_dist.get_edge_probs(swarm.composite_graph, inputs=input_dict)\n",
    "    \n",
    "    # Move edge_probs to CPU memory\n",
    "    edge_probs = edge_probs.cpu()\n",
    "    \n",
    "    all_edge_probs.append(edge_probs)\n",
    "\n",
    "\n",
    "# Stack all edge_probs into a tensor\n",
    "all_edge_probs = torch.stack(all_edge_probs)\n",
    "\n",
    "# Calculate mean edge_probs\n",
    "mean_edge_probs = torch.mean(all_edge_probs, dim=0)\n",
    "'''\n",
    "# Initialize list to store distances and corresponding records\n",
    "distances = []\n",
    "\n",
    "for record in dataset_val:\n",
    "    record_copy = copy.deepcopy(record)\n",
    "    record_df = pd.DataFrame([record_copy])\n",
    "    input_dict = dataset_val.record_to_swarm_input(record_df)\n",
    "    edge_probs = swarm.connection_dist.get_edge_probs(swarm.composite_graph, inputs=input_dict)\n",
    "    \n",
    "    # Calculate distance to the mean\n",
    "    distance = torch.norm(edge_probs - mean_edge_probs)\n",
    "    \n",
    "    # Store distance and record\n",
    "    distances.append((distance, record_copy, edge_probs))\n",
    "# Sort distances in descending order and keep top 10\n",
    "top_10_records = sorted(distances, key=lambda x: x[0], reverse=True)[:10]\n",
    "\n",
    "# Extract records from tuples\n",
    "top_10_records = [(record, edge_probs) for _, record, edge_probs  in top_10_records]\n",
    "print(\"top10:\")\n",
    "for record,probs in top_10_records:\n",
    "    print(\"Question: \", record)\n",
    "    _print_conns(probs, swarm)\n",
    "    print(\"Subtracting the mean: \")\n",
    "    _print_conns(mean_edge_probs-probs ,swarm)\n",
    "    print(\"----NExt-----\")\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from experiments.evaluator.evaluator import Evaluator\n",
    "evaluator = Evaluator(\n",
    "        swarm,\n",
    "        None,\n",
    "        dataset_val,\n",
    "        model_name=\"google/gemma-7B-it\",\n",
    "        enable_tensorboard = False,\n",
    "        enable_artifacts=True,\n",
    "        tensorboard_tag=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record,probs in top_10_records:\n",
    "    print(\"Question: \", record)\n",
    "    _print_conns(probs, swarm)\n",
    "    print(\"Subtracting the mean: \")\n",
    "    _print_conns(mean_edge_probs-probs ,swarm)\n",
    "    print(\"----NExt-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0210, 0.0028, 0.0504, 0.2718, 0.1899, 0.0477, 0.5472, 0.0464, 0.0574,\n",
      "        0.1615, 0.4172, 0.0243, 0.0391, 0.1500, 0.7945, 0.0444, 0.9224, 0.0947,\n",
      "        0.9115, 0.1136, 0.1830, 0.3965, 0.0025, 0.0117, 0.0508, 0.7961, 0.9366,\n",
      "        0.0068, 0.6100, 0.0106, 0.0369, 0.9150, 0.3006, 0.0933, 0.7040, 0.2444,\n",
      "        0.0241, 0.0735, 0.0134, 0.0972, 0.0752, 0.0380, 0.5021, 0.0251, 0.0845,\n",
      "        0.0708, 0.0875, 0.9951, 0.2662, 0.0042, 0.0091, 0.0349, 0.6201, 0.0886,\n",
      "        0.7485, 0.0521, 0.0447, 0.1086, 0.2114, 0.7146, 0.6430, 0.8371, 0.2215,\n",
      "        0.4389])\n",
      "tensor([0.0043, 0.0007, 0.0092, 0.0420, 0.0453, 0.0096, 0.0440, 0.0102, 0.0150,\n",
      "        0.0248, 0.0479, 0.0043, 0.0074, 0.0280, 0.0415, 0.0080, 0.0080, 0.0153,\n",
      "        0.0174, 0.0224, 0.0301, 0.0416, 0.0005, 0.0025, 0.0092, 0.0231, 0.0182,\n",
      "        0.0014, 0.0410, 0.0023, 0.0067, 0.0127, 0.0472, 0.0329, 0.0496, 0.0377,\n",
      "        0.0055, 0.0333, 0.0033, 0.0205, 0.0132, 0.0089, 0.0383, 0.0063, 0.0160,\n",
      "        0.0110, 0.0158, 0.0012, 0.0354, 0.0010, 0.0020, 0.0073, 0.0492, 0.0194,\n",
      "        0.0516, 0.0128, 0.0076, 0.0185, 0.0341, 0.0378, 0.0466, 0.0254, 0.0298,\n",
      "        0.0519])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "Mean: \n",
      "0: src=google/gemma-7B-it(67VD), dst=vivo-ai/BlueLM-7B-Chat(4JNc), prob=0.017\n",
      "1: src=google/gemma-7B-it(67VD), dst=google/gemma-7B-it(UJda), prob=0.003\n",
      "2: src=google/gemma-7B-it(67VD), dst=vivo-ai/BlueLM-7B-Chat(Nk7H), prob=0.055\n",
      "3: src=google/gemma-7B-it(67VD), dst=google/gemma-7B-it(3Gsk), prob=0.329\n",
      "4: src=google/gemma-7B-it(67VD), dst=vivo-ai/BlueLM-7B-Chat(4fen), prob=0.219\n",
      "5: src=google/gemma-7B-it(67VD), dst=google/gemma-7B-it(3jrD), prob=0.052\n",
      "6: src=google/gemma-7B-it(67VD), dst=vivo-ai/BlueLM-7B-Chat(338e), prob=0.488\n",
      "7: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=google/gemma-7B-it(67VD), prob=0.060\n",
      "8: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=google/gemma-7B-it(UJda), prob=0.067\n",
      "9: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=vivo-ai/BlueLM-7B-Chat(Nk7H), prob=0.176\n",
      "10: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=google/gemma-7B-it(3Gsk), prob=0.352\n",
      "11: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=vivo-ai/BlueLM-7B-Chat(4fen), prob=0.020\n",
      "12: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=google/gemma-7B-it(3jrD), prob=0.043\n",
      "13: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=vivo-ai/BlueLM-7B-Chat(338e), prob=0.130\n",
      "14: src=google/gemma-7B-it(UJda), dst=google/gemma-7B-it(67VD), prob=0.752\n",
      "15: src=google/gemma-7B-it(UJda), dst=vivo-ai/BlueLM-7B-Chat(4JNc), prob=0.047\n",
      "16: src=google/gemma-7B-it(UJda), dst=vivo-ai/BlueLM-7B-Chat(Nk7H), prob=0.933\n",
      "17: src=google/gemma-7B-it(UJda), dst=google/gemma-7B-it(3Gsk), prob=0.100\n",
      "18: src=google/gemma-7B-it(UJda), dst=vivo-ai/BlueLM-7B-Chat(4fen), prob=0.890\n",
      "19: src=google/gemma-7B-it(UJda), dst=google/gemma-7B-it(3jrD), prob=0.131\n",
      "20: src=google/gemma-7B-it(UJda), dst=vivo-ai/BlueLM-7B-Chat(338e), prob=0.142\n",
      "21: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=google/gemma-7B-it(67VD), prob=0.448\n",
      "22: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=vivo-ai/BlueLM-7B-Chat(4JNc), prob=0.002\n",
      "23: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=google/gemma-7B-it(UJda), prob=0.009\n",
      "24: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=google/gemma-7B-it(3Gsk), prob=0.057\n",
      "25: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=vivo-ai/BlueLM-7B-Chat(4fen), prob=0.834\n",
      "26: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=google/gemma-7B-it(3jrD), prob=0.919\n",
      "27: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=vivo-ai/BlueLM-7B-Chat(338e), prob=0.008\n",
      "28: src=google/gemma-7B-it(3Gsk), dst=google/gemma-7B-it(67VD), prob=0.564\n",
      "29: src=google/gemma-7B-it(3Gsk), dst=vivo-ai/BlueLM-7B-Chat(4JNc), prob=0.010\n",
      "30: src=google/gemma-7B-it(3Gsk), dst=google/gemma-7B-it(UJda), prob=0.036\n",
      "31: src=google/gemma-7B-it(3Gsk), dst=vivo-ai/BlueLM-7B-Chat(Nk7H), prob=0.923\n",
      "32: src=google/gemma-7B-it(3Gsk), dst=vivo-ai/BlueLM-7B-Chat(4fen), prob=0.313\n",
      "33: src=google/gemma-7B-it(3Gsk), dst=google/gemma-7B-it(3jrD), prob=0.092\n",
      "34: src=google/gemma-7B-it(3Gsk), dst=vivo-ai/BlueLM-7B-Chat(338e), prob=0.696\n",
      "35: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=google/gemma-7B-it(67VD), prob=0.295\n",
      "36: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=vivo-ai/BlueLM-7B-Chat(4JNc), prob=0.017\n",
      "37: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=google/gemma-7B-it(UJda), prob=0.085\n",
      "38: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=vivo-ai/BlueLM-7B-Chat(Nk7H), prob=0.015\n",
      "39: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=google/gemma-7B-it(3Gsk), prob=0.074\n",
      "40: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=google/gemma-7B-it(3jrD), prob=0.057\n",
      "41: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=vivo-ai/BlueLM-7B-Chat(338e), prob=0.051\n",
      "42: src=google/gemma-7B-it(3jrD), dst=google/gemma-7B-it(67VD), prob=0.517\n",
      "43: src=google/gemma-7B-it(3jrD), dst=vivo-ai/BlueLM-7B-Chat(4JNc), prob=0.023\n",
      "44: src=google/gemma-7B-it(3jrD), dst=google/gemma-7B-it(UJda), prob=0.086\n",
      "45: src=google/gemma-7B-it(3jrD), dst=vivo-ai/BlueLM-7B-Chat(Nk7H), prob=0.047\n",
      "46: src=google/gemma-7B-it(3jrD), dst=google/gemma-7B-it(3Gsk), prob=0.090\n",
      "47: src=google/gemma-7B-it(3jrD), dst=vivo-ai/BlueLM-7B-Chat(4fen), prob=0.994\n",
      "48: src=google/gemma-7B-it(3jrD), dst=vivo-ai/BlueLM-7B-Chat(338e), prob=0.213\n",
      "49: src=vivo-ai/BlueLM-7B-Chat(338e), dst=google/gemma-7B-it(67VD), prob=0.004\n",
      "50: src=vivo-ai/BlueLM-7B-Chat(338e), dst=vivo-ai/BlueLM-7B-Chat(4JNc), prob=0.011\n",
      "51: src=vivo-ai/BlueLM-7B-Chat(338e), dst=google/gemma-7B-it(UJda), prob=0.030\n",
      "52: src=vivo-ai/BlueLM-7B-Chat(338e), dst=vivo-ai/BlueLM-7B-Chat(Nk7H), prob=0.586\n",
      "53: src=vivo-ai/BlueLM-7B-Chat(338e), dst=google/gemma-7B-it(3Gsk), prob=0.086\n",
      "54: src=vivo-ai/BlueLM-7B-Chat(338e), dst=vivo-ai/BlueLM-7B-Chat(4fen), prob=0.672\n",
      "55: src=vivo-ai/BlueLM-7B-Chat(338e), dst=google/gemma-7B-it(3jrD), prob=0.056\n",
      "56: src=google/gemma-7B-it(67VD), dst=FinalDecision(6D3k), prob=0.047\n",
      "57: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=FinalDecision(6D3k), prob=0.126\n",
      "58: src=google/gemma-7B-it(UJda), dst=FinalDecision(6D3k), prob=0.262\n",
      "59: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=FinalDecision(6D3k), prob=0.756\n",
      "60: src=google/gemma-7B-it(3Gsk), dst=FinalDecision(6D3k), prob=0.645\n",
      "61: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=FinalDecision(6D3k), prob=0.852\n",
      "62: src=google/gemma-7B-it(3jrD), dst=FinalDecision(6D3k), prob=0.217\n",
      "63: src=vivo-ai/BlueLM-7B-Chat(338e), dst=FinalDecision(6D3k), prob=0.481\n",
      "Variance: \n",
      "0: src=google/gemma-7B-it(67VD), dst=vivo-ai/BlueLM-7B-Chat(4JNc), prob=0.004\n",
      "1: src=google/gemma-7B-it(67VD), dst=google/gemma-7B-it(UJda), prob=0.001\n",
      "2: src=google/gemma-7B-it(67VD), dst=vivo-ai/BlueLM-7B-Chat(Nk7H), prob=0.009\n",
      "3: src=google/gemma-7B-it(67VD), dst=google/gemma-7B-it(3Gsk), prob=0.042\n",
      "4: src=google/gemma-7B-it(67VD), dst=vivo-ai/BlueLM-7B-Chat(4fen), prob=0.045\n",
      "5: src=google/gemma-7B-it(67VD), dst=google/gemma-7B-it(3jrD), prob=0.010\n",
      "6: src=google/gemma-7B-it(67VD), dst=vivo-ai/BlueLM-7B-Chat(338e), prob=0.044\n",
      "7: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=google/gemma-7B-it(67VD), prob=0.010\n",
      "8: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=google/gemma-7B-it(UJda), prob=0.015\n",
      "9: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=vivo-ai/BlueLM-7B-Chat(Nk7H), prob=0.025\n",
      "10: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=google/gemma-7B-it(3Gsk), prob=0.048\n",
      "11: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=vivo-ai/BlueLM-7B-Chat(4fen), prob=0.004\n",
      "12: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=google/gemma-7B-it(3jrD), prob=0.007\n",
      "13: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=vivo-ai/BlueLM-7B-Chat(338e), prob=0.028\n",
      "14: src=google/gemma-7B-it(UJda), dst=google/gemma-7B-it(67VD), prob=0.042\n",
      "15: src=google/gemma-7B-it(UJda), dst=vivo-ai/BlueLM-7B-Chat(4JNc), prob=0.008\n",
      "16: src=google/gemma-7B-it(UJda), dst=vivo-ai/BlueLM-7B-Chat(Nk7H), prob=0.008\n",
      "17: src=google/gemma-7B-it(UJda), dst=google/gemma-7B-it(3Gsk), prob=0.015\n",
      "18: src=google/gemma-7B-it(UJda), dst=vivo-ai/BlueLM-7B-Chat(4fen), prob=0.017\n",
      "19: src=google/gemma-7B-it(UJda), dst=google/gemma-7B-it(3jrD), prob=0.022\n",
      "20: src=google/gemma-7B-it(UJda), dst=vivo-ai/BlueLM-7B-Chat(338e), prob=0.030\n",
      "21: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=google/gemma-7B-it(67VD), prob=0.042\n",
      "22: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=vivo-ai/BlueLM-7B-Chat(4JNc), prob=0.000\n",
      "23: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=google/gemma-7B-it(UJda), prob=0.003\n",
      "24: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=google/gemma-7B-it(3Gsk), prob=0.009\n",
      "25: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=vivo-ai/BlueLM-7B-Chat(4fen), prob=0.023\n",
      "26: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=google/gemma-7B-it(3jrD), prob=0.018\n",
      "27: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=vivo-ai/BlueLM-7B-Chat(338e), prob=0.001\n",
      "28: src=google/gemma-7B-it(3Gsk), dst=google/gemma-7B-it(67VD), prob=0.041\n",
      "29: src=google/gemma-7B-it(3Gsk), dst=vivo-ai/BlueLM-7B-Chat(4JNc), prob=0.002\n",
      "30: src=google/gemma-7B-it(3Gsk), dst=google/gemma-7B-it(UJda), prob=0.007\n",
      "31: src=google/gemma-7B-it(3Gsk), dst=vivo-ai/BlueLM-7B-Chat(Nk7H), prob=0.013\n",
      "32: src=google/gemma-7B-it(3Gsk), dst=vivo-ai/BlueLM-7B-Chat(4fen), prob=0.047\n",
      "33: src=google/gemma-7B-it(3Gsk), dst=google/gemma-7B-it(3jrD), prob=0.033\n",
      "34: src=google/gemma-7B-it(3Gsk), dst=vivo-ai/BlueLM-7B-Chat(338e), prob=0.050\n",
      "35: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=google/gemma-7B-it(67VD), prob=0.038\n",
      "36: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=vivo-ai/BlueLM-7B-Chat(4JNc), prob=0.005\n",
      "37: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=google/gemma-7B-it(UJda), prob=0.033\n",
      "38: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=vivo-ai/BlueLM-7B-Chat(Nk7H), prob=0.003\n",
      "39: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=google/gemma-7B-it(3Gsk), prob=0.020\n",
      "40: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=google/gemma-7B-it(3jrD), prob=0.013\n",
      "41: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=vivo-ai/BlueLM-7B-Chat(338e), prob=0.009\n",
      "42: src=google/gemma-7B-it(3jrD), dst=google/gemma-7B-it(67VD), prob=0.038\n",
      "43: src=google/gemma-7B-it(3jrD), dst=vivo-ai/BlueLM-7B-Chat(4JNc), prob=0.006\n",
      "44: src=google/gemma-7B-it(3jrD), dst=google/gemma-7B-it(UJda), prob=0.016\n",
      "45: src=google/gemma-7B-it(3jrD), dst=vivo-ai/BlueLM-7B-Chat(Nk7H), prob=0.011\n",
      "46: src=google/gemma-7B-it(3jrD), dst=google/gemma-7B-it(3Gsk), prob=0.016\n",
      "47: src=google/gemma-7B-it(3jrD), dst=vivo-ai/BlueLM-7B-Chat(4fen), prob=0.001\n",
      "48: src=google/gemma-7B-it(3jrD), dst=vivo-ai/BlueLM-7B-Chat(338e), prob=0.035\n",
      "49: src=vivo-ai/BlueLM-7B-Chat(338e), dst=google/gemma-7B-it(67VD), prob=0.001\n",
      "50: src=vivo-ai/BlueLM-7B-Chat(338e), dst=vivo-ai/BlueLM-7B-Chat(4JNc), prob=0.002\n",
      "51: src=vivo-ai/BlueLM-7B-Chat(338e), dst=google/gemma-7B-it(UJda), prob=0.007\n",
      "52: src=vivo-ai/BlueLM-7B-Chat(338e), dst=vivo-ai/BlueLM-7B-Chat(Nk7H), prob=0.049\n",
      "53: src=vivo-ai/BlueLM-7B-Chat(338e), dst=google/gemma-7B-it(3Gsk), prob=0.019\n",
      "54: src=vivo-ai/BlueLM-7B-Chat(338e), dst=vivo-ai/BlueLM-7B-Chat(4fen), prob=0.052\n",
      "55: src=vivo-ai/BlueLM-7B-Chat(338e), dst=google/gemma-7B-it(3jrD), prob=0.013\n",
      "56: src=google/gemma-7B-it(67VD), dst=FinalDecision(6D3k), prob=0.008\n",
      "57: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=FinalDecision(6D3k), prob=0.018\n",
      "58: src=google/gemma-7B-it(UJda), dst=FinalDecision(6D3k), prob=0.034\n",
      "59: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=FinalDecision(6D3k), prob=0.038\n",
      "60: src=google/gemma-7B-it(3Gsk), dst=FinalDecision(6D3k), prob=0.047\n",
      "61: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=FinalDecision(6D3k), prob=0.025\n",
      "62: src=google/gemma-7B-it(3jrD), dst=FinalDecision(6D3k), prob=0.030\n",
      "63: src=vivo-ai/BlueLM-7B-Chat(338e), dst=FinalDecision(6D3k), prob=0.052\n"
     ]
    }
   ],
   "source": [
    "print(all_edge_probs[:][0])\n",
    "all_probs_variance = torch.std(all_edge_probs, dim=0)\n",
    "print(all_probs_variance)\n",
    "all_probs_mean = torch.mean(all_edge_probs, dim=0)\n",
    "print(all_probs_variance.shape)\n",
    "print(all_probs_mean.shape)\n",
    "print(\"Mean: \")\n",
    "_print_conns(all_probs_mean, swarm)\n",
    "print(\"Variance: \")\n",
    "_print_conns(all_probs_variance, swarm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean: \n",
    "0: src=DirectAnswer(5Q3h), dst=CoTStep(6RLA), prob=0.997\n",
    "1: src=DirectAnswer(5Q3h), dst=CoTStep(6Y3D), prob=0.001\n",
    "2: src=DirectAnswer(5Q3h), dst=CoTStep(8y3C), prob=0.646\n",
    "3: src=CoTStep(6RLA), dst=DirectAnswer(5Q3h), prob=0.001\n",
    "4: src=CoTStep(6Y3D), dst=DirectAnswer(5Q3h), prob=0.001\n",
    "5: src=CoTStep(8y3C), dst=DirectAnswer(5Q3h), prob=0.000\n",
    "6: src=DirectAnswer(5Q3h), dst=FinalDecision(7fFJ), prob=0.988\n",
    "7: src=CoTStep(6RLA), dst=FinalDecision(7fFJ), prob=0.169\n",
    "8: src=CoTStep(6Y3D), dst=FinalDecision(7fFJ), prob=0.004\n",
    "9: src=CoTStep(8y3C), dst=FinalDecision(7fFJ), prob=0.918\n",
    "Variance: \n",
    "0: src=DirectAnswer(5Q3h), dst=CoTStep(6RLA), prob=0.000\n",
    "1: src=DirectAnswer(5Q3h), dst=CoTStep(6Y3D), prob=0.000\n",
    "2: src=DirectAnswer(5Q3h), dst=CoTStep(8y3C), prob=0.000\n",
    "3: src=CoTStep(6RLA), dst=DirectAnswer(5Q3h), prob=0.000\n",
    "4: src=CoTStep(6Y3D), dst=DirectAnswer(5Q3h), prob=0.000\n",
    "5: src=CoTStep(8y3C), dst=DirectAnswer(5Q3h), prob=0.000\n",
    "6: src=DirectAnswer(5Q3h), dst=FinalDecision(7fFJ), prob=0.000\n",
    "7: src=CoTStep(6RLA), dst=FinalDecision(7fFJ), prob=0.000\n",
    "8: src=CoTStep(6Y3D), dst=FinalDecision(7fFJ), prob=0.000\n",
    "9: src=CoTStep(8y3C), dst=FinalDecision(7fFJ), prob=0.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 9)\n",
      "0: src=google/gemma-7B-it(67VD), dst=vivo-ai/BlueLM-7B-Chat(4JNc), prob=0.175\n",
      "1: src=google/gemma-7B-it(67VD), dst=google/gemma-7B-it(UJda), prob=0.047\n",
      "2: src=google/gemma-7B-it(67VD), dst=vivo-ai/BlueLM-7B-Chat(Nk7H), prob=0.732\n",
      "3: src=google/gemma-7B-it(67VD), dst=google/gemma-7B-it(3Gsk), prob=0.219\n",
      "4: src=google/gemma-7B-it(67VD), dst=vivo-ai/BlueLM-7B-Chat(4fen), prob=0.156\n",
      "5: src=google/gemma-7B-it(67VD), dst=google/gemma-7B-it(3jrD), prob=0.062\n",
      "6: src=google/gemma-7B-it(67VD), dst=vivo-ai/BlueLM-7B-Chat(338e), prob=0.115\n",
      "7: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=google/gemma-7B-it(67VD), prob=0.056\n",
      "8: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=google/gemma-7B-it(UJda), prob=0.101\n",
      "9: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=vivo-ai/BlueLM-7B-Chat(Nk7H), prob=0.024\n",
      "10: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=google/gemma-7B-it(3Gsk), prob=0.040\n",
      "11: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=vivo-ai/BlueLM-7B-Chat(4fen), prob=0.072\n",
      "12: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=google/gemma-7B-it(3jrD), prob=0.178\n",
      "13: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=vivo-ai/BlueLM-7B-Chat(338e), prob=0.132\n",
      "14: src=google/gemma-7B-it(UJda), dst=google/gemma-7B-it(67VD), prob=0.040\n",
      "15: src=google/gemma-7B-it(UJda), dst=vivo-ai/BlueLM-7B-Chat(4JNc), prob=0.309\n",
      "16: src=google/gemma-7B-it(UJda), dst=vivo-ai/BlueLM-7B-Chat(Nk7H), prob=0.157\n",
      "17: src=google/gemma-7B-it(UJda), dst=google/gemma-7B-it(3Gsk), prob=0.644\n",
      "18: src=google/gemma-7B-it(UJda), dst=vivo-ai/BlueLM-7B-Chat(4fen), prob=0.678\n",
      "19: src=google/gemma-7B-it(UJda), dst=google/gemma-7B-it(3jrD), prob=0.025\n",
      "20: src=google/gemma-7B-it(UJda), dst=vivo-ai/BlueLM-7B-Chat(338e), prob=0.088\n",
      "21: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=google/gemma-7B-it(67VD), prob=0.042\n",
      "22: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=vivo-ai/BlueLM-7B-Chat(4JNc), prob=0.097\n",
      "23: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=google/gemma-7B-it(UJda), prob=0.053\n",
      "24: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=google/gemma-7B-it(3Gsk), prob=0.179\n",
      "25: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=vivo-ai/BlueLM-7B-Chat(4fen), prob=0.054\n",
      "26: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=google/gemma-7B-it(3jrD), prob=0.309\n",
      "27: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=vivo-ai/BlueLM-7B-Chat(338e), prob=0.223\n",
      "28: src=google/gemma-7B-it(3Gsk), dst=google/gemma-7B-it(67VD), prob=0.039\n",
      "29: src=google/gemma-7B-it(3Gsk), dst=vivo-ai/BlueLM-7B-Chat(4JNc), prob=0.045\n",
      "30: src=google/gemma-7B-it(3Gsk), dst=google/gemma-7B-it(UJda), prob=0.086\n",
      "31: src=google/gemma-7B-it(3Gsk), dst=vivo-ai/BlueLM-7B-Chat(Nk7H), prob=0.030\n",
      "32: src=google/gemma-7B-it(3Gsk), dst=vivo-ai/BlueLM-7B-Chat(4fen), prob=0.057\n",
      "33: src=google/gemma-7B-it(3Gsk), dst=google/gemma-7B-it(3jrD), prob=0.326\n",
      "34: src=google/gemma-7B-it(3Gsk), dst=vivo-ai/BlueLM-7B-Chat(338e), prob=0.760\n",
      "35: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=google/gemma-7B-it(67VD), prob=0.068\n",
      "36: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=vivo-ai/BlueLM-7B-Chat(4JNc), prob=0.070\n",
      "37: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=google/gemma-7B-it(UJda), prob=0.044\n",
      "38: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=vivo-ai/BlueLM-7B-Chat(Nk7H), prob=0.151\n",
      "39: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=google/gemma-7B-it(3Gsk), prob=0.125\n",
      "40: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=google/gemma-7B-it(3jrD), prob=0.076\n",
      "41: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=vivo-ai/BlueLM-7B-Chat(338e), prob=0.063\n",
      "42: src=google/gemma-7B-it(3jrD), dst=google/gemma-7B-it(67VD), prob=0.099\n",
      "43: src=google/gemma-7B-it(3jrD), dst=vivo-ai/BlueLM-7B-Chat(4JNc), prob=0.003\n",
      "44: src=google/gemma-7B-it(3jrD), dst=google/gemma-7B-it(UJda), prob=0.018\n",
      "45: src=google/gemma-7B-it(3jrD), dst=vivo-ai/BlueLM-7B-Chat(Nk7H), prob=0.036\n",
      "46: src=google/gemma-7B-it(3jrD), dst=google/gemma-7B-it(3Gsk), prob=0.090\n",
      "47: src=google/gemma-7B-it(3jrD), dst=vivo-ai/BlueLM-7B-Chat(4fen), prob=0.016\n",
      "48: src=google/gemma-7B-it(3jrD), dst=vivo-ai/BlueLM-7B-Chat(338e), prob=0.333\n",
      "49: src=vivo-ai/BlueLM-7B-Chat(338e), dst=google/gemma-7B-it(67VD), prob=0.024\n",
      "50: src=vivo-ai/BlueLM-7B-Chat(338e), dst=vivo-ai/BlueLM-7B-Chat(4JNc), prob=0.007\n",
      "51: src=vivo-ai/BlueLM-7B-Chat(338e), dst=google/gemma-7B-it(UJda), prob=0.024\n",
      "52: src=vivo-ai/BlueLM-7B-Chat(338e), dst=vivo-ai/BlueLM-7B-Chat(Nk7H), prob=0.090\n",
      "53: src=vivo-ai/BlueLM-7B-Chat(338e), dst=google/gemma-7B-it(3Gsk), prob=0.191\n",
      "54: src=vivo-ai/BlueLM-7B-Chat(338e), dst=vivo-ai/BlueLM-7B-Chat(4fen), prob=0.181\n",
      "55: src=vivo-ai/BlueLM-7B-Chat(338e), dst=google/gemma-7B-it(3jrD), prob=0.061\n",
      "56: src=google/gemma-7B-it(67VD), dst=FinalDecision(6D3k), prob=0.635\n",
      "57: src=vivo-ai/BlueLM-7B-Chat(4JNc), dst=FinalDecision(6D3k), prob=0.140\n",
      "58: src=google/gemma-7B-it(UJda), dst=FinalDecision(6D3k), prob=0.235\n",
      "59: src=vivo-ai/BlueLM-7B-Chat(Nk7H), dst=FinalDecision(6D3k), prob=0.161\n",
      "60: src=google/gemma-7B-it(3Gsk), dst=FinalDecision(6D3k), prob=0.314\n",
      "61: src=vivo-ai/BlueLM-7B-Chat(4fen), dst=FinalDecision(6D3k), prob=0.220\n",
      "62: src=google/gemma-7B-it(3jrD), dst=FinalDecision(6D3k), prob=0.433\n",
      "63: src=vivo-ai/BlueLM-7B-Chat(338e), dst=FinalDecision(6D3k), prob=0.462\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Assuming create_adjacency_matrix and _print_conns are defined elsewhere.\n",
    "\n",
    "# Sample data generation (replace this with actual data retrieval)\n",
    "edge_probs = torch.sigmoid(swarm.connection_dist.edge_logits)\n",
    "# _print_conns(edge_probs, swarm)\n",
    "#edge_probs = all_probs_mean  # Assuming all_probs_mean is defined.\n",
    "# Simulating edge probabilities for demonstration:\n",
    "# Create the adjacency matrix from edge probabilities\n",
    "# adjacency_matrix, node_indices, names = create_adjacency_matrix(edge_probs, swarm)\n",
    "# For demonstration, let's use the edge_probs as the adjacency matrix:\n",
    "adjacency_matrix,node_indices,names = create_adjacency_matrix(edge_probs, swarm)\n",
    "#reorder the matrix\n",
    "reorder=True\n",
    "if reorder:\n",
    "    print((adjacency_matrix[1::2,:]).shape)\n",
    "    adjacency_matrix = np.concatenate([adjacency_matrix[0,:][np.newaxis,:], adjacency_matrix[1::2,:], adjacency_matrix[2::2,:]], 0)\n",
    "    adjacency_matrix = np.concatenate([adjacency_matrix[:,0][:,np.newaxis], adjacency_matrix[:,1::2], adjacency_matrix[:,2::2]], 1)\n",
    "_print_conns(edge_probs, swarm)\n",
    "node_indices = {i: i for i in range(9)}\n",
    "names = {i: f\"Node {i}\" for i in range(9)}\n",
    "\n",
    "# Plotting the heatmap with the reversed 'RdBu' colormap\n",
    "fig, ax = plt.subplots()\n",
    "heatmap = ax.imshow(adjacency_matrix, cmap='RdBu_r', vmin=0, vmax=1)  # Note the '_r' to reverse the colormap\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = plt.colorbar(heatmap)\n",
    "\n",
    "# Set the tick labels\n",
    "num_nodes = len(node_indices)\n",
    "ax.set_xticks(np.arange(num_nodes))\n",
    "ax.set_yticks(np.arange(num_nodes))\n",
    "ax.set_xticklabels([names[node_id] for node_id in node_indices])\n",
    "ax.set_yticklabels([names[node_id] for node_id in node_indices])\n",
    "\n",
    "# Rotate the tick labels for better readability\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "\n",
    "# Set the axis labels\n",
    "ax.set_xlabel('Destination Node')\n",
    "ax.set_ylabel('Source Node')\n",
    "\n",
    "# Set the title\n",
    "ax.set_title('Node Connectivity Probability Heatmap')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump the edge probs as pickle object\n",
    "with open(full_path, 'wb') as f:\n",
    "    pickle_object['mean_cmmlu'] = all_probs_mean\n",
    "    pickle.dump(pickle_object,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix = np.stack([adjacency_matrix[0::2,:], adjacency_matrix[1::2,:]])\n",
    "adjacency_matrix = np.stack([adjacency_matrix[:,0::2], adjacency_matrix[:,1::2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix = np.stack([adjacency_matrix[0::2,:], adjacency_matrix[1::2,:]])\n",
    "adjacency_matrix = np.stack([adjacency_matrix[:,0::2], adjacency_matrix[:,1::2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix = np.stack([adjacency_matrix[0::2,:], adjacency_matrix[1::2,:]])\n",
    "adjacency_matrix = np.stack([adjacency_matrix[:,0::2], adjacency_matrix[:,1::2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(swarm.connection_dist.model.linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(model=\"google/gemma-7B-it\", dtype=\"half\", max_model_len=5888)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-7B-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = [{\"role\": \"user\", \"content\": \"Write a poem about cats.\"}]\n",
    "prompt = tokenizer.apply_chat_template(message, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "sampling_params = SamplingParams(temperature=0.8, top_p=0.95, top_k=50,max_tokens=2000)\n",
    "outputs = llm.generate(prompt,sampling_params=sampling_params)\n",
    "# Print the outputs.\n",
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install accelerate\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-7B-it\")\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"google/gemma-7B-it\",torch_dtype=torch.bfloat16).to(\"cuda\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-7B-it\", torch_dtype=torch.bfloat16).to(\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tokenizer.special_tokens_map)\n",
    "#dummy message\n",
    "message = [{\"role\": \"user\", \"content\": \"Write a poem about cats.\"}]\n",
    "prompt = tokenizer.apply_chat_template(message, tokenize=False, add_generation_prompt=True)\n",
    "prompt = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\").to(\"cuda\")\n",
    "prompt_len = len(prompt[0])\n",
    "outputs = model.generate(\n",
    "            prompt,\n",
    "            do_sample=True,\n",
    "            max_length=2000,\n",
    "            top_k=50,\n",
    "            top_p=1.0\n",
    "        )\n",
    "output_text = tokenizer.decode(outputs[0][prompt.shape[-1]:],skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the GPTChat class\n",
    "gpt_chat = CustomLLM()\n",
    "#gpt_chat_2 = CustomLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#if gpt_chat is gpt_chat_2:\n",
    "#    print(\"Same instance\")\n",
    "# Create a list of Message objects\n",
    "messages = [Message(role=\"user\", content=\"What would a dog say if he could speak?\")]\n",
    "# Move messages to GPU\n",
    "# Create tasks for the gen method\n",
    "tasks = [asyncio.create_task(gpt_chat.agen(messages))]#, asyncio.create_task(gpt_chat_2.agen(messages))]\n",
    "\n",
    "# Wait for the tasks to complete and get the results\n",
    "results = [await task for task in tasks]\n",
    "\n",
    "# Print the output\n",
    "print(results)\n",
    "#print(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_connections = [0 for _ in range(188)]\n",
    "init_connection_probability = 0.1\n",
    "domain = \"crosswords\"\n",
    "llm_backbone_name=\"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm = Swarm([\"CrosswordsReflection\", \"CrosswordsToT\", \"CrosswordsBruteForceOpt\"], \"crosswords\", \"gpt-3.5-turbo-1106\", #\"gpt-4-1106-preview\"\n",
    "            final_node_class=\"ReturnAll\", \n",
    "            final_node_kwargs={},\n",
    "            edge_optimize=True,\n",
    "            init_connection_probability=init_connection_probability, \n",
    "            connect_output_nodes_to_final_node=connect_output_nodes_to_final_node, \n",
    "            include_inner_agent_connections=include_inner_agent_connections,\n",
    "            edge_network_enable=edge_network_enable,\n",
    "            llm_backbone_name=llm_backbone_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_network = EdgeNetwork(llm_backbone_name=llm_backbone_name, num_edges=len(potential_connections), initial_probability=init_connection_probability)\n",
    "connection_dist = EdgeWiseDistributionByModel(potential_connections, edge_network, domain)\n",
    "\n",
    "connection_dist.load_state_dict(torch.load(\"result/crosswords/experiment_edge_logits_10.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of EdgeNetwork\n",
    "num_edges = 188  # Replace with the number of edges used when saving the model\n",
    "llm_backbone_name = 'gpt2'  # Replace with the name of the model used when saving the model\n",
    "model = EdgeNetwork(llm_backbone_name, num_edges)\n",
    "\n",
    "# Load the state dictionary\n",
    "state_dict = torch.load('result/crosswords/experiment_edge_logits_10.pt')\n",
    "\n",
    "# Remove 'model.' prefix from state dictionary keys and exclude 'order_params'\n",
    "state_dict = {k.replace('model.', ''): v for k, v in state_dict.items() if k != 'model.order_params'}\n",
    "\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of EdgeNetwork\n",
    "num_edges = 188  # Replace with the number of edges used when saving the model\n",
    "llm_backbone_name = 'gpt2'  # Replace with the name of the model used when saving the model\n",
    "model = EdgeNetwork(llm_backbone_name, num_edges)\n",
    "\n",
    "# Load the state dictionary\n",
    "state_dict = torch.load('result/crosswords/experiment_edge_logits_10.pt')\n",
    "\n",
    "# Remove 'model.' prefix from state dictionary keys\n",
    "state_dict = {k.replace('model.', ''): v for k, v in state_dict.items()}\n",
    "\n",
    "model.load_state_dict(state_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weak_to_strong",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
